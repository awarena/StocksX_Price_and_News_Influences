{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77fea524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init spark session to read data from parquet files\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from stocksx.configs.spark_config import SparkConfig\n",
    "from stocksx.data_pipeline.sub_modules.spark_manager import SparkManager\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "905830a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Verifying Configuration ===\n",
      "Testing Spark basic functionality...\n",
      "Using package root: e:\\projects\\stocksx_price_and_news_influences\n",
      "Iceberg warehouse: file:///e:/projects/stocksx_price_and_news_influences/data/warehouse/iceberg\n",
      "Hive warehouse: file:///e:/projects/stocksx_price_and_news_influences/data/warehouse/hive\n",
      "Found PostgreSQL JDBC driver at: e:\\projects\\stocksx_price_and_news_influences\\stocksx\\libs\\postgresql-42.7.5.jar\n",
      "Created Spark session with:\n",
      "- Iceberg enabled: True\n",
      "- Hive metastore: True\n",
      "- Warehouse dir: file:///e:/projects/stocksx_price_and_news_influences/data/warehouse/iceberg\n",
      "- Hive config dir: e:\\projects\\stocksx_price_and_news_influences\\stocksx\\configs\n",
      "Basic Spark functionality: OK (1+1=2)\n",
      "\n",
      "Initializing Hive metastore schema...\n",
      "Initializing Hive metastore schema...\n",
      "Hive metastore schema already exists.\n",
      "\n",
      "Testing Iceberg functionality...\n",
      "Iceberg functionality: OK\n",
      "\n",
      "Testing Hive metastore...\n",
      "Database result schema:\n",
      "root\n",
      " |-- namespace: string (nullable = false)\n",
      "\n",
      "Found databases: ['default', 'iceberg_test', 'raw_data']\n",
      "Hive metastore functionality: OK\n",
      "Dropped test database\n",
      "\n",
      "Verification complete!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark_config = SparkConfig(iceberg_enabled=True, iceberg_namespace = \"raw_data\", \n",
    "                           iceberg_warehouse=\"data/warehouse/iceberg\")\n",
    "spark_manager = SparkManager(spark_config)\n",
    "spark_manager.verify_configuration()\n",
    "spark = spark_manager.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3da41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n",
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "| raw_data|\n",
      "+---------+\n",
      "\n",
      "+---------+------------+-----------+\n",
      "|namespace|   tableName|isTemporary|\n",
      "+---------+------------+-----------+\n",
      "| raw_data|stock_prices|      false|\n",
      "+---------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all available catalogs\n",
    "spark.sql(\"SHOW CATALOGS\").show()\n",
    "\n",
    "# List all namespaces in the local catalog\n",
    "spark.sql(\"SHOW NAMESPACES IN spark_catalog\").show()\n",
    "\n",
    "# List all tables in the specified namespace\n",
    "spark.sql(\"SHOW TABLES IN raw_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c745e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "home_directory = os.path.dirname(os.path.dirname(current_directory))\n",
    "\n",
    "metadata_path = os.path.join(home_directory, \"data\", \"metadata\", \"stock_updates_metadata\", \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2acef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f3a585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technology_symbols = metadata_df[metadata_df['sector'] == 'Technology']['symbol'].tolist()\n",
    "len(technology_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05d5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = spark.read.table(\"raw_data.stock_prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a704f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: ['AAOI', 'AAPL', 'ACIW', 'ACLS', 'ACMR', 'ACN', 'ADBE', 'ADEA', 'ADI', 'ADP', 'ADSK', 'ADTN', 'AEHR', 'AEVA', 'AEYE', 'AFRM', 'AGMH', 'AGYS', 'AI', 'AIFF', 'AIOT', 'AIP', 'AIRG', 'AISP', 'AIXI', 'AKAM', 'ALAB', 'ALAR', 'ALGM', 'ALIT', 'ALKT', 'ALLT', 'ALNT', 'ALOT', 'ALRM', 'ALTS', 'AMAT', 'AMBA', 'AMD', 'AMKR', 'AMOD', 'AMPG', 'AMPGW', 'AMPL', 'AMST', 'ANET', 'ANSS', 'AOSL', 'APCX', 'APH', 'API', 'APLD', 'APP', 'APPF', 'APPN', 'APPS', 'ARBB', 'ARBE', 'ARM', 'ARQQ', 'ARQQW', 'ARRY', 'ARW', 'ASAN', 'ASGN', 'ASML', 'ASNS', 'ASTC', 'ASTI', 'ASTS', 'ASUR', 'ASX', 'ASYS', 'ATCH', 'ATEN', 'ATGL', 'ATOM', 'AUDC', 'AUID', 'AUR', 'AUUD', 'AVDX', 'AVGO', 'AVNW', 'AVPT', 'AVT', 'AWRE', 'AXIL', 'AXTI', 'AZ', 'BAND', 'BASE', 'BB', 'BBAI', 'BDC', 'BEEM', 'BELFA', 'BELFB', 'BHE', 'BIGC']\n",
      "Processing batch: ['BILL', 'BKKT', 'BKTI', 'BL', 'BLBX', 'BLIN', 'BLKB', 'BLND', 'BLZE', 'BMI', 'BMR', 'BNAI', 'BNZI', 'BOSC', 'BOX', 'BOXL', 'BR', 'BRZE', 'BSY', 'BTCM', 'BTCT', 'BTDR', 'BZAI', 'CACI', 'CALX', 'CAMT', 'CAN', 'CCCS', 'CCRD', 'CCSI', 'CDNS', 'CDW', 'CETX', 'CEVA', 'CFLT', 'CGNT', 'CGNX', 'CHKP', 'CIEN', 'CINT', 'CLBT', 'CLFD', 'CLMB', 'CLPS', 'CLRO', 'CLS', 'CLVT', 'CMBM', 'CMTL', 'CNDT', 'CNTM', 'CNXC', 'CNXN', 'COHR', 'COHU', 'COMM', 'CORZ', 'CPAY', 'CPSH', 'CRCT', 'CRDO', 'CREX', 'CRM', 'CRNC', 'CRNT', 'CRSR', 'CRUS', 'CRWD', 'CSAI', 'CSCO', 'CSGS', 'CSIQ', 'CSPI', 'CTLP', 'CTM', 'CTS', 'CTSH', 'CVLT', 'CWAN', 'CXAI', 'CXM', 'CYBR', 'CYCU', 'CYN', 'DAIO', 'DAKT', 'DATS', 'DATSW', 'DAVA', 'DAVE', 'DAY', 'DBD', 'DBX', 'DCBO', 'DDD', 'DDOG', 'DELL', 'DFIN', 'DGII', 'DHX']\n",
      "Processing batch: ['DIOD', 'DJCO', 'DLO', 'DMRC', 'DOCN', 'DOCU', 'DOMO', 'DOX', 'DQ', 'DSGX', 'DSP', 'DSWL', 'DT', 'DTSS', 'DTST', 'DUOL', 'DUOT', 'DV', 'DVLT', 'DXC', 'EBON', 'EEFT', 'EGAN', 'EGHT', 'ELSE', 'ELTK', 'ELWS', 'ENPH', 'ENTG', 'EPAM', 'EPWK', 'ERIC', 'ESE', 'ESTC', 'ETWO', 'EVCM', 'EVTC', 'EXFY', 'EXLS', 'EXOD', 'EXTR', 'FAAS', 'FARO', 'FCUV', 'FEBO', 'FEIM', 'FFIV', 'FI', 'FICO', 'FIS', 'FIVN', 'FKWL', 'FLEX', 'FLYW', 'FMTO', 'FN', 'FORM', 'FORTY', 'FOUR', 'FOXX', 'FRGT', 'FROG', 'FRSH', 'FSLR', 'FSLY', 'FTCI', 'FTFT', 'FTNT', 'FTV', 'G', 'GAUZ', 'GB', 'GCT', 'GCTS', 'GDDY', 'GDS', 'GDYN', 'GEN', 'GFS', 'GIB', 'GILT', 'GLE', 'GLOB', 'GLW', 'GMM', 'GNSS', 'GPRO', 'GRAB', 'GRABW', 'GRMN', 'GRND', 'GRRR', 'GSIT', 'GTLB', 'GWRE', 'HCKT', 'HIMX', 'HIT', 'HKD', 'HKIT']\n",
      "Processing batch: ['HLIT', 'HOLO', 'HPAI', 'HPE', 'HPQ', 'HTCR', 'HUBC', 'HUBS', 'IBEX', 'IBM', 'IBTA', 'ICG', 'ICHR', 'IDAI', 'IDCC', 'IDN', 'IFBD', 'III', 'IIIV', 'IMMR', 'IMOS', 'IMTE', 'IMXI', 'INDI', 'INFA', 'INFY', 'INGM', 'INLX', 'INOD', 'INSG', 'INTA', 'INTC', 'INTT', 'INTU', 'INTZ', 'INUV', 'IONQ', 'IOT', 'IPGP', 'IPM', 'IT', 'ITRI', 'ITRN', 'IZM', 'JAMF', 'JBL', 'JDZG', 'JFU', 'JKHY', 'JKS', 'JNPR', 'JTAI', 'JZ', 'KARO', 'KC', 'KD', 'KEYS', 'KLAC', 'KLIC', 'KLTR', 'KN', 'KNW', 'KOPN', 'KOSS', 'KPLT', 'KSPI', 'KTCC', 'KULR', 'KVYO', 'LAES', 'LASR', 'LAW', 'LDOS', 'LDTC', 'LEDS', 'LFUS', 'LGCL', 'LGL', 'LIDR', 'LIDRW', 'LIF', 'LINK', 'LITE', 'LOGI', 'LPL', 'LPSN', 'LPTH', 'LRCX', 'LSAK', 'LSCC', 'LSPD', 'LTRX', 'LYFT', 'LYTS', 'LZMH', 'MANH', 'MAPS', 'MASK', 'MAXN', 'MCHP']\n",
      "Processing batch: ['MCRP', 'MDB', 'MEI', 'MFH', 'MFI', 'MGIC', 'MIND', 'MITK', 'MITQ', 'MKSI', 'MLAB', 'MLGO', 'MLNK', 'MNDO', 'MNDY', 'MOBX', 'MOGO', 'MPTI', 'MPWR', 'MQ', 'MRAM', 'MRIN', 'MRT', 'MRVL', 'MSAI', 'MSFT', 'MSI', 'MSN', 'MSTR', 'MTC', 'MTEK', 'MTLS', 'MTSI', 'MU', 'MVIS', 'MX', 'MXL', 'NATL', 'NCNO', 'NEON', 'NET', 'NICE', 'NN', 'NNDM', 'NOK', 'NOTE', 'NOVA', 'NOVT', 'NOW', 'NRDY', 'NSIT', 'NTAP', 'NTCL', 'NTCT', 'NTGR', 'NTNX', 'NTWK', 'NUKK', 'NUKKW', 'NVDA', 'NVEC', 'NVMI', 'NVNI', 'NVTS', 'NXPI', 'NXPL', 'NXT', 'NXTT', 'NYAX', 'OBLG', 'OCC', 'OCFT', 'ODD', 'ODYS', 'OKTA', 'OLB', 'OLED', 'OLO', 'ON', 'ONDS', 'ONTF', 'ONTO', 'OOMA', 'OPTX', 'ORCL', 'ORKT', 'OS', 'OSIS', 'OSPN', 'OSS', 'OST', 'OTEX', 'OUST', 'PAGS', 'PANW', 'PAR', 'PATH', 'PAY', 'PAYC', 'PAYO']\n",
      "Processing batch: ['PAYS', 'PAYX', 'PCOR', 'PCTY', 'PD', 'PDFS', 'PDYN', 'PDYNW', 'PEGA', 'PENG', 'PERF', 'PET', 'PGY', 'PGYWW', 'PHUN', 'PI', 'PLAB', 'PLTR', 'PLUS', 'PLXS', 'PN', 'POET', 'PONY', 'POWI', 'PRCH', 'PRGS', 'PRO', 'PRSO', 'PRTH', 'PSFE', 'PSN', 'PSQH', 'PSTG', 'PTC', 'PUBM', 'PXLW', 'QBTS', 'QCOM', 'QH', 'QLYS', 'QMCO', 'QRVO', 'QTWO', 'QUBT', 'QUIK', 'QXO', 'RAMP', 'RBBN', 'RBRK', 'RCAT', 'RDVT', 'RDWR', 'RDZN', 'REFR', 'REKR', 'RELL', 'RELY', 'RGTI', 'RIME', 'RMNI', 'RNG', 'ROG', 'ROP', 'RPAY', 'RPD', 'RSKD', 'RSSS', 'RUN', 'RVYL', 'RXT', 'RYDE', 'RZLV', 'S', 'SABR', 'SAGT', 'SAIC', 'SAIH', 'SAIL', 'SANG', 'SANM', 'SAP', 'SATS', 'SATX', 'SCKT', 'SCSC', 'SEDG', 'SELX', 'SEMR', 'SGMA', 'SGN', 'SHLS', 'SHOP', 'SILC', 'SIMO', 'SITM', 'SKYT', 'SLAB', 'SMCI', 'SMRT', 'SMSI']\n",
      "Processing batch: ['SMTC', 'SMTK', 'SMWB', 'SMXT', 'SNCR', 'SNDK', 'SNOW', 'SNPS', 'SNX', 'SOBR', 'SOL', 'SONM', 'SONO', 'SONY', 'SOPA', 'SOTK', 'SOUN', 'SPNS', 'SPRU', 'SPSC', 'SPT', 'SQNS', 'SRAD', 'SSNC', 'SSTI', 'SSYS', 'ST', 'STEC', 'STM', 'STNE', 'STRK', 'STX', 'SUNE', 'SVCO', 'SVRE', 'SWKS', 'SYNA', 'SYNX', 'SYT', 'SYTA', 'TACT', 'TAIT', 'TAOP', 'TASK', 'TBCH', 'TCX', 'TDC', 'TDTH', 'TDY', 'TEAM', 'TEL', 'TENB', 'TER', 'TGL', 'TIXT', 'TLS', 'TOST', 'TOYO', 'TRAK', 'TRMB', 'TRT', 'TSAT', 'TSEM', 'TSM', 'TSSI', 'TTAN', 'TTD', 'TTEC', 'TTGT', 'TTMI', 'TURB', 'TUYA', 'TWLO', 'TXN', 'TYGO', 'TYL', 'U', 'UAVS', 'UBER', 'UBXG', 'UCTT', 'UEIC', 'UI', 'UIS', 'ULY', 'UMC', 'UPBD', 'UPLD', 'USIO', 'UTSI', 'VECO', 'VEEA', 'VERB', 'VERI', 'VERX', 'VHC', 'VIAV', 'VICR', 'VLN', 'VMEO']\n",
      "Processing batch: ['VNET', 'VNT', 'VPG', 'VRAR', 'VRNS', 'VRNT', 'VRRM', 'VRSN', 'VS', 'VSAT', 'VSH', 'VSSYW', 'VSTE', 'VTEX', 'VTSI', 'VUZI', 'VVPR', 'VYX', 'WATT', 'WBX', 'WCT', 'WDAY', 'WDC', 'WETO', 'WEX', 'WIT', 'WIX', 'WK', 'WKEY', 'WLDS', 'WNS', 'WOLF', 'WRAP', 'WRD', 'WTO', 'WYY', 'XBP', 'XNET', 'XPER', 'XRX', 'XTKG', 'XYZ', 'YAAS', 'YALA', 'YEXT', 'YIBO', 'YMM', 'YOU', 'YXT', 'ZBRA', 'ZENA', 'ZENV', 'ZEO', 'ZEPP', 'ZETA', 'ZM', 'ZS', 'ZSPC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[symbol: string, trade_date: date, open: double, high: double, low: double, close: double, volume: bigint]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Create empty Spark DataFrame to hold the results\n",
    "technology_stocks_df = spark.createDataFrame([], stocks_df.schema)\n",
    "\n",
    "for i in range(0, len(technology_symbols), 100):\n",
    "    symbols_batch = technology_symbols[i:i + 100]\n",
    "    print(f\"Processing batch: {symbols_batch}\")\n",
    "    \n",
    "    # Create a DataFrame from the list of symbols\n",
    "    symbols_batch_df = spark.createDataFrame(symbols_batch, \"string\").toDF(\"symbol\")\n",
    "    \n",
    "    technology_stocks_df = stocks_df.join(broadcast(symbols_batch_df), \"symbol\")\n",
    "\n",
    "technology_stocks_df.cache()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf270_stocks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
